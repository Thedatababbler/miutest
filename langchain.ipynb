{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import LlamaCpp\n",
    "from langchain.llms import OpenAI, HuggingFaceHub#,HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"DATA/POLYP/test/CVC-300/images/185.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "test_text = 'What is in this image'\n",
    "#And return your answer in a dict format like a dict:{\"object\":\"\", \"color\":\"\", \"shape\":\"\", \"location\":\"\"}'\n",
    "#Return your answer in a dict format like this:{\"object\":\"ulcer\", \"color\":\"pale\", \"shape\":\"round\", \"location\":\"rectum\"}'\n",
    "\n",
    "# payload = [\n",
    "# #   \"model\": \"gpt-4-vision-preview\",\n",
    "#   HumanMessage(\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": test_text,#'What is this image',\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#           }\n",
    "#         }\n",
    "#       ]\n",
    "#     } )\n",
    "#   ],\n",
    "#   \"max_tokens\": 2000\n",
    "# ]\n",
    "p =     [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": test_text},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is in this image\n"
     ]
    }
   ],
   "source": [
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", request_timeout=15, temperature=0)\n",
    "dd = chat.invoke(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This image appears to be an endoscopic view of an internal organ, most likely')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "dd = '/project/project/GLIP/MIU-VL/OUTPUTS/polyp/hybrid/zero_shot/bbone/llm/top1/eval/glip_large_model_o365_goldg/inference/val/bbox.json'\n",
    "\n",
    "import json\n",
    "\n",
    "with open(dd) as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4182645862.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_160374/4182645862.py\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    \"type\": \"image_url\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "# OpenAI API Key\n",
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/project/project/GLIP/MIU-VL/DATA/TN3k/images/test/0046.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "headers = {\n",
    "\"Content-Type\": \"application/json\",\n",
    "\"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "test_text = 'What is the color and shape of the polyp in the image, and describe its color and shape in the following format.\\\n",
    "for example, you should return an output like this:{\"color\":\"pale\", \"shape\":\"bump\"}'\n",
    "# test_text = 'Can you identify the round shape dark hole in this image and share the x_min, y_min, x_max and y_max in 0-1 normalized space. Only return the numbers, nothing else.'\n",
    "\n",
    "\n",
    "payload = {\n",
    "\"model\": \"gpt-4-vision-preview\",\n",
    "\"messages\": [\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": test_text,#'What is this image',\n",
    "    },]\n",
    "    {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }\n",
    "    }\n",
    "    ]\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 2000\n",
    "    }\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())\n",
    "print(response.json()['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8UgWL3bdESxUqVTYGPW4krrGWWsWE', 'object': 'chat.completion', 'created': 1702323981, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 297, 'completion_tokens': 24, 'total_tokens': 321}, 'choices': [{'message': {'role': 'assistant', 'content': 'The round or oval shape that is darker than the surrounding background pattern is located in the bottom right area of the image.'}, 'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0}]}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/project/project/GLIP/MIU-VL/DATA/TN3k/images/test/0046.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "test_text = 'Locate the round or oval shape area that is darker than surrounding background pattern. Just tell me its in upper right or upper left or bottom right or bottom left or center area'\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": test_text\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"/project/project/GLIP/MIU-VL/DATA/TN3k/images/test/0046.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "test_text = 'Locate the round or oval shape area that is darker than surrounding background pattern.'\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"gpt-4-vision-preview\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": test_text\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
